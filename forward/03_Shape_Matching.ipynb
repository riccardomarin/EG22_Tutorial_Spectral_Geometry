{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03 - Shape Matching.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxBJXE4L1hgDQotKUvyJn/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riccardomarin/EG22_Tutorial_Spectral_Geometry/blob/main/forward/03_Shape_Matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the principal application of the spectral shape analysis is shape matching! Here we provide a complete tour from the basics to the state of the art refinement involved"
      ],
      "metadata": {
        "id": "AywwZi6RlmbM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TD7A8hZk1NFF"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/riccardomarin/EG22_Tutorial_Spectral_Geometry/main/data/tr_reg_090.off\n",
        "!wget https://raw.githubusercontent.com/riccardomarin/EG22_Tutorial_Spectral_Geometry/main/data/tr_reg_043.off\n",
        "!wget https://raw.githubusercontent.com/riccardomarin/EG22_Tutorial_Spectral_Geometry/main/utils/utils_mesh.py\n",
        "!wget https://raw.githubusercontent.com/riccardomarin/EG22_Tutorial_Spectral_Geometry/main/utils/utils_spectral.py\n",
        "\n",
        "!pip install plyfile\n",
        "\n",
        "import os \n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import scipy.io as sio\n",
        "import scipy.sparse.linalg\n",
        "from scipy.sparse.linalg import eigsh\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch  \n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt \n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from utils_spectral import LB_FEM_sparse, EigendecompositionSparse, LB_cotan, Eigendecomposition\n",
        "from utils_mesh import load_off\n",
        "from utils_mesh import plot_colormap, plot_RGBmap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, we load two shapes"
      ],
      "metadata": {
        "id": "Tp-07t_w17PD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tr_reg_090.off\") as f:\n",
        "  v_src, f_src = load_off(f)\n",
        "  f_src = np.asarray(f_src).astype('long')\n",
        "\n",
        "with open(\"tr_reg_043.off\") as f:\n",
        "  v_tar, f_tar = load_off(f)\n",
        "  f_tar = np.asarray(f_tar).astype('long')\n",
        "\n",
        "p = plot_colormap([v_src,v_tar], [f_src, f_tar],[np.ones(v_src.shape[0])]*2)\n",
        "p.show()"
      ],
      "metadata": {
        "id": "ppKB8i6N1-MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These shapes are naturally in correspondence, since they share the same connectivity (trinagulation). Hence, we can define a function on one shape, and use this correspondence to transfer the function on the other."
      ],
      "metadata": {
        "id": "5tgDC5iU8hLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "funz_ = (v_tar - np.min(v_tar,0))/np.tile((np.max(v_tar,0)-np.min(v_tar,0)),(np.size(v_tar,0),1));\n",
        "colors = np.cos(funz_);\n",
        "funz_tar = (colors-np.min(colors))/(np.max(colors) - np.min(colors));\n",
        "\n",
        "p = plot_RGBmap([v_src, v_tar], [f_src,f_tar],[funz_tar,funz_tar])\n",
        "p.show()"
      ],
      "metadata": {
        "id": "mAGHwXiZxZPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matching by descriptors\n",
        "\n",
        "# WKS\n",
        "\n",
        "We will use the Wave Kernel Signature (WKS) descriptor to do the matching. Recall the formula:\n",
        "\n",
        "$K_E(x,x) = \\sum\\limits_{l=1}^{\\infty}e^{- \\frac{(log(E) - log(\\lambda_l))^2}{2\\sigma^2}} \\phi_l(x)^2 $\n",
        "\n",
        "Where:\n",
        "- $sigma = 7 \\delta$\n",
        "- $delta =  (e_{max} - e{min})/ M$\n",
        "- $e_{max} = log(E_N) - 2\\sigma$\n",
        "- $e_{min} = log(E_1) + 2\\sigma$\n",
        "- $E_N$ is the max eigenvalue in absolute value\n",
        "- $E_1$ is the min non-zero eigenvalue in absolute value\n",
        "- $M$ is the number of WKS scales\n",
        "\n",
        "The steps are:\n",
        "- Reading the meshes, computing the LBO eigenvectors\n",
        "- Defining the WKS computation\n",
        "- Visualizing the WKS scales on meshes\n",
        "- Performing the matching using WKS (Nearest-Neighbor in the descriptor space)\n",
        "- Visualizing the matching (and computing the error)\n",
        "\n",
        "Are the descriptors coherent among the shapes, for different descriptor scales? Is the matching good? We can change the number of descriptors: does it impact the matching?"
      ],
      "metadata": {
        "id": "mcMdMVO9SrhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the WKS descriptor\n",
        "def WKS(vertices, faces, evals, evecs, wks_size, variance):\n",
        "    # Number of vertices\n",
        "    n = vertices.shape[0]\n",
        "    WKS = np.zeros((n,wks_size))\n",
        "\n",
        "    # Just for numerical stability\n",
        "    evals[evals<1e-6] = 1e-6\n",
        "\n",
        "    # log(E)\n",
        "    log_E = np.log(evals).T\n",
        "\n",
        "    # Defining the energies step\n",
        "    e = np.linspace(log_E[1], np.max(log_E)/1.02, wks_size)\n",
        "\n",
        "    # Computing the sigma\n",
        "    sigma = (e[1]-e[0]) * variance\n",
        "    C = np.zeros((wks_size,1))\n",
        "\n",
        "    for i in np.arange(0,wks_size):\n",
        "        # Computing WKS\n",
        "        WKS[:,i] = np.sum(\n",
        "            (evecs)**2 * np.tile( np.exp((-(e[i] - log_E)**2) / (2*sigma**2)),(n,1)), axis=1)\n",
        "        \n",
        "        # Normalization\n",
        "        C[i] = np.sum(np.exp((-(e[i]-log_E)**2)/(2*sigma**2)))\n",
        "        \n",
        "    WKS = np.divide(WKS,np.tile(C,(1,n)).T)\n",
        "    return WKS"
      ],
      "metadata": {
        "id": "1k6v8Nl2XfJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = 'float32'\n",
        "k = 100\n",
        "\n",
        "# === COMPUING LBO EIGENFUNCTIONS ===\n",
        "v_src_t = torch.from_numpy(v_src.astype(dtype)).cuda()*1\n",
        "f_src_t = torch.from_numpy(np.asarray(f_src).astype('long')).cuda()\n",
        "\n",
        "L_sym_sp, A_sp_src, Ainv_sp = LB_FEM_sparse(v_src_t, f_src_t.long())\n",
        "evecs_src, evals_src = EigendecompositionSparse(L_sym_sp.values(),L_sym_sp.indices(), torch.tensor(k), torch.tensor(L_sym_sp.shape[-1]))\n",
        "evecs_src = evecs_src * Ainv_sp[:,None]\n",
        "\n",
        "v_tar_t = torch.from_numpy(v_tar.astype(dtype)).cuda()*1\n",
        "f_tar_t = torch.from_numpy(np.asarray(f_tar).astype('long')).cuda()\n",
        "\n",
        "L_sym_sp, A_sp_tar, Ainv_sp = LB_FEM_sparse(v_tar_t, f_tar_t.long())\n",
        "evecs_tar, evals_tar = EigendecompositionSparse(L_sym_sp.values(),L_sym_sp.indices(), torch.tensor(k), torch.tensor(L_sym_sp.shape[-1]))\n",
        "evecs_tar = evecs_tar * Ainv_sp[:,None]\n",
        "\n",
        "# === SAVING IN NUMPY ===\n",
        "evecs_tar = evecs_tar.detach().cpu().numpy()\n",
        "evals_tar = evals_tar.detach().cpu().numpy()\n",
        "\n",
        "evecs_src = evecs_src.detach().cpu().numpy()\n",
        "evals_src = evals_src.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "c6VVd66yXxtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy as sp\n",
        "\n",
        "# Computing the descriptors for the two shapes\n",
        "d_src = WKS(v_src, f_src, evals_src, evecs_src, 100, 7)\n",
        "d_tar = WKS(v_tar, f_tar, evals_tar, evecs_tar, 100, 7)\n",
        "\n",
        "# Nearest Neighbor to obtain the p2p map\n",
        "treesearch = sp.spatial.cKDTree(d_src)\n",
        "p2p = treesearch.query(d_tar, k=1)[1]\n",
        "\n",
        "# To see the quality of the matching we plot a function on one shape and we transfer it to the other\n",
        "funz_ = (v_src - np.min(v_src,0))/np.tile((np.max(v_src,0)-np.min(v_src,0)),(np.size(v_src,0),1));\n",
        "colors = np.cos(funz_);\n",
        "funz_src = (colors-np.min(colors))/(np.max(colors) - np.min(colors));\n",
        "\n",
        "p = plot_RGBmap([v_src, v_tar], [f_src,f_tar],[funz_src,funz_src[p2p,:]])\n",
        "p.show()\n",
        "\n",
        "# Computing (euclidean) error evaluation\n",
        "err = np.sum(np.square(v_tar - v_tar[p2p,:]))\n",
        "print(err)"
      ],
      "metadata": {
        "id": "iHYtfjdP5obN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functional Maps\n",
        "\n",
        "Instead to directly match the point signatures, we can use them to align the eigenfunctions of the two shapes. \n",
        "\n",
        "Here we deploy a basic optimization for Functional Maps framework, to recover the functional map $C$. We optimize $C$ for the following loss:\n",
        "\n",
        "$ Loss(C) = w_1 \\|CA - B \\|_2 + w_2 \\|C\\Lambda_{src} - \\Lambda_{tar}C\\|$\n",
        "\n",
        "The first term is the descriptor preservation term (i.e., $C$ should map the  source shape descriptors' coefficients $A$ to the correct coefficient $B$ on the target shape), and the second term is the commutativity with the Laplacian (that promotes isometric maps)."
      ],
      "metadata": {
        "id": "XPG9cAEsaEgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recovering useful variables\n",
        "evecs_tar = evecs_tar\n",
        "evals_tar = evals_tar\n",
        "evecs_src = evecs_src\n",
        "evals_src = evals_src\n",
        "A_src = np.diag(A_sp_src.cpu().detach().numpy())\n",
        "A_tar = np.diag(A_sp_tar.cpu().detach().numpy())\n",
        "\n",
        "# Computing descriptors\n",
        "n_land =  6\n",
        "\n",
        "n_wks  =  20\n",
        "n_evals = 20\n",
        "\n",
        "# Landmarks, as step functions randomly sampled\n",
        "step = np.int(np.ceil(v_src.shape[0] / n_land))\n",
        "a = np.arange(0,v_src.shape[0],step)\n",
        "landmarks = np.zeros((v_src.shape[0], a.size))\n",
        "landmarks[a,np.arange(a.size)] = 1\n",
        "\n",
        "# WKS\n",
        "d_src = WKS(v_src, f_src, evals_src, evecs_src, n_wks, 7)\n",
        "d_tar = WKS(v_tar, f_tar, evals_tar, evecs_tar, n_wks, 7)\n",
        "\n",
        "# Optimization Process\n",
        "desc_src = np.hstack((landmarks,d_src))\n",
        "desc_tar = np.hstack((landmarks,d_tar))"
      ],
      "metadata": {
        "id": "5EVQNrASZc4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptor normalization\n",
        "no = np.sqrt(np.diag(np.matmul(A_src.__matmul__(desc_src).T, desc_src)))\n",
        "no_s = np.tile(no.T,(v_src.shape[0],1))\n",
        "no_t = np.tile(no.T,(v_tar.shape[0],1))\n",
        "fct_src = np.divide(desc_src,no_s)\n",
        "fct_tar = np.divide(desc_tar,no_t)\n",
        "\n",
        "# Coefficents of the obtained descriptors\n",
        "Fct_src = np.matmul(A_src.T.__matmul__(evecs_src[:, 0:n_evals]).T, fct_src)\n",
        "Fct_tar = np.matmul(A_tar.T.__matmul__(evecs_tar[:, 0:n_evals]).T, fct_tar)\n",
        "\n",
        "# The relation between the two constant functions can be computed in a closed form\n",
        "constFct = np.zeros((n_evals,1))\n",
        "constFct[0, 0] = np.sign(evecs_src[0, 0] * evecs_tar[0, 0]) * np.sqrt(np.sum(A_tar)/np.sum(A_src))"
      ],
      "metadata": {
        "id": "zcGkyyNya-fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Energy weights\n",
        "w1 = 1e-1 # Descriptors preservation\n",
        "w2 = 1e-8 # Commutativity with Laplacian\n",
        "\n",
        "# Define tensorflow objects\n",
        "fs = torch.Tensor(Fct_src)\n",
        "ft = torch.Tensor(Fct_tar)\n",
        "evals = torch.diag(torch.Tensor(np.reshape(np.float32(evals_src[0:n_evals]), (n_evals,))))\n",
        "evalt = torch.diag(torch.Tensor(np.reshape(np.float32(evals_tar[0:n_evals]), (n_evals,))))"
      ],
      "metadata": {
        "id": "PLujNjaVbC0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are ready to run the optimization!"
      ],
      "metadata": {
        "id": "W3K4dPMc0QME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import progressbar\n",
        "C_ini = np.zeros((n_evals,n_evals))\n",
        "C_ini[0,0]=constFct[0,0]\n",
        "C = Variable(torch.Tensor(C_ini), requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.Adam([C], lr=5e-2)\n",
        "\n",
        "for it in progressbar.progressbar(range(1500)):   \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Loss computation\n",
        "    loss1 = w1 * torch.sum(((torch.matmul(C, fs) - ft) ** 2)) / 2 # Descriptor preservation\n",
        "    loss2 = w2 * torch.sum((torch.matmul(C, evals) - torch.matmul(evalt,C))**2) # Commute with Laplacian\n",
        "    loss = torch.sum(loss1  + loss2)\n",
        "\n",
        "    # Gradient descent\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "C8NbcHYccXsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can visualize the obtained $C$ and the correspondence. To compute the correspondence we can use the obtained $C$ to transfer the delta functions and then perform Nearest-Neighbor in the space of the aligned bases."
      ],
      "metadata": {
        "id": "20RInEVR0awK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing C matrix\n",
        "C_np = C.detach().numpy()\n",
        "plt.imshow(C_np)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# Point-to-point correspondence computation\n",
        "treesearch = sp.spatial.cKDTree(np.matmul(evecs_src[:,0:n_evals], C_np.T))\n",
        "p2p = treesearch.query(evecs_tar[:,0:n_evals], k=1)[1]\n",
        "\n",
        "# Correspondence visualization\n",
        "funz_ = (v_src - np.min(v_src,0))/np.tile((np.max(v_src,0)-np.min(v_src,0)),(np.size(v_src,0),1));\n",
        "colors = np.cos(funz_);\n",
        "funz_src = (colors-np.min(colors))/(np.max(colors) - np.min(colors));\n",
        "\n",
        "p = plot_RGBmap([v_src, v_tar], [f_src,f_tar],[funz_src,funz_src[p2p,:]])\n",
        "p.show()\n",
        "\n",
        "# Computing (euclidean) error evaluation\n",
        "err = np.sum(np.square(v_tar - v_tar[p2p,:]))\n",
        "print(err)"
      ],
      "metadata": {
        "id": "UT2Jd8uohPYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that FMAP matching is much smoother than the one obtained by WKS, and the numerical error significantly decreases!"
      ],
      "metadata": {
        "id": "YMK554f_1C3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ICP Refinement\n",
        "The correspondence can be post-processed by ICP registration in the eigenfunction space!"
      ],
      "metadata": {
        "id": "XK4gvYSq0-WR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('ICP refine...')\n",
        "C_ICP = C_np\n",
        "\n",
        "# ICP Refining\n",
        "for k in np.arange(0,5):\n",
        "    treesearch = scipy.spatial.cKDTree(np.matmul(evecs_src[:,0:n_evals],C_ICP.T))\n",
        "    matches = treesearch.query(evecs_tar[:,0:n_evals], k=1)[1]\n",
        "    W = np.linalg.lstsq(evecs_tar[matches, 0:n_evals],evecs_src[:, 0:n_evals])[0]\n",
        "    d = np.linalg.svd(W)\n",
        "    C_ICP = np.matmul(np.matmul(d[0], np.eye(n_evals)), d[2])\n",
        "\n",
        "# C Visualization\n",
        "plt.imshow(C_ICP)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# Correspondence visualization \n",
        "treesearch = scipy.spatial.cKDTree(np.matmul(evecs_src[:,0:n_evals],C_ICP.T))\n",
        "p2p_icp = treesearch.query(evecs_tar[:,0:n_evals], k=1)[1]\n",
        "\n",
        "# Correspondence visualization\n",
        "funz_ = (v_src - np.min(v_src,0))/np.tile((np.max(v_src,0)-np.min(v_src,0)),(np.size(v_src,0),1));\n",
        "colors = np.cos(funz_);\n",
        "funz_src = (colors-np.min(colors))/(np.max(colors) - np.min(colors));\n",
        "\n",
        "p = plot_RGBmap([v_src, v_tar], [f_src,f_tar],[funz_src,funz_src[p2p_icp,:]])\n",
        "p.show()\n",
        "\n",
        "# Computing (euclidean) error evaluation\n",
        "err = np.sum(np.square(v_tar - v_tar[p2p_icp,:]))\n",
        "print(err)"
      ],
      "metadata": {
        "id": "kUdyX_Ppi_5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ZoomOut refinement\n",
        "\n",
        "Finally, a state of the art post-processing is ZoomOut. This lets us include much more frequencies without explicitly solving a costly optimization."
      ],
      "metadata": {
        "id": "XMWupcw81sYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# More iterations => bigger map => higher frequencies => better quality\n",
        "n_iter = 10\n",
        "\n",
        "# ZOOMOUT\n",
        "C_iter = C_ICP\n",
        "for i in np.arange(0,n_iter):\n",
        "  # 1) Convert into dense correspondence\n",
        "  treesearch = scipy.spatial.cKDTree(np.matmul(evecs_src[:,0:n_evals+i],C_iter.T))\n",
        "  p2p_ = treesearch.query(evecs_tar[:,0:n_evals+i], k=1)[1]\n",
        " \n",
        "  #2) Convert into C of dimension (n+1) x (n+1)\n",
        "  C_iter = np.matmul(np.linalg.pinv(evecs_tar[:,0:n_evals+i+1]),evecs_src[p2p_,0:n_evals+i+1])\n",
        "\n",
        "\n",
        "# Evaluate the map and visualize the result\n",
        "plt.imshow(C_iter)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# Correspondence visualization \n",
        "treesearch = sp.spatial.cKDTree(np.matmul(evecs_src[:,0:n_evals+n_iter],C_iter.T))\n",
        "p2p_zo = treesearch.query(evecs_tar[:,0:n_evals+n_iter], k=1)[1]\n",
        "\n",
        "# Correspondence visualization\n",
        "funz_ = (v_src - np.min(v_src,0))/np.tile((np.max(v_src,0)-np.min(v_src,0)),(np.size(v_src,0),1));\n",
        "colors = np.cos(funz_);\n",
        "funz_src = (colors-np.min(colors))/(np.max(colors) - np.min(colors));\n",
        "\n",
        "p = plot_RGBmap([v_src, v_tar], [f_src,f_tar],[funz_src,funz_src[p2p_zo,:]])\n",
        "p.show()\n",
        "\n",
        "# Computing error evaluation\n",
        "err = np.sum(np.square(v_tar - v_tar[p2p_zo,:]))\n",
        "print(err)"
      ],
      "metadata": {
        "id": "fxiZvYBxjEIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To better appreciate the improvements, we can plot all the methods togheter and show a function with higher frequencies."
      ],
      "metadata": {
        "id": "8hKYwFB12R4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correspondence visualization\n",
        "funz_ = (v_src - np.min(v_src,0))/np.tile((np.max(v_src,0)-np.min(v_src,0)),(np.size(v_src,0),1));\n",
        "colors = np.cos(funz_);\n",
        "funz_src = (colors-np.min(colors))/(np.max(colors) - np.min(colors));\n",
        "\n",
        "# Higher frequencies function\n",
        "funz_src  = np.cos(funz_src * 10)\n",
        "\n",
        "p = plot_RGBmap([v_src, v_tar, v_tar, v_tar, v_tar], [f_src,f_tar, f_tar,f_tar,f_tar,f_tar],\n",
        "                [funz_src, funz_src, funz_src[p2p,:],funz_src[p2p_icp,:],funz_src[p2p_zo,:]])\n",
        "p.show()"
      ],
      "metadata": {
        "id": "kuh063WsjXiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the left: \n",
        "\n",
        "Source - Target (GT) - Target (FMAP) - Target (FMAP + ICP) - Target (FMAP + ICP + ZO)"
      ],
      "metadata": {
        "id": "2fsWEGeY4Xi7"
      }
    }
  ]
}