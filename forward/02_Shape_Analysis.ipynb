{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02 - Shape Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKx5rUrV7n5Mo+XZBQXy0S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riccardomarin/EG22_Tutorial_Spectral_Geometry/blob/main/forward/02_Shape_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will replicate some of our consideration for Graphs on 3D surfaces"
      ],
      "metadata": {
        "id": "eQfFbj1UYEhO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAkZEglKFBqj"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/riccardomarin/EG22_Tutorial_Spectral_Geometry/main/data/tr_reg_090.off\n",
        "!wget https://raw.githubusercontent.com/riccardomarin/EG22_Tutorial_Spectral_Geometry/main/data/tr_reg_043.off\n",
        "!wget https://github.com/riccardomarin/EG22_Tutorial_Spectral_Geometry/raw/main/data/pose.mat\n",
        "!wget https://github.com/riccardomarin/EG22_Tutorial_Spectral_Geometry/raw/main/data/style.mat\n",
        "\n",
        "!wget https://raw.githubusercontent.com/riccardomarin/EG22_Tutorial_Spectral_Geometry/main/utils/utils_mesh.py\n",
        "!wget https://raw.githubusercontent.com/riccardomarin/EG22_Tutorial_Spectral_Geometry/main/utils/utils_spectral.py\n",
        "\n",
        "!pip install plyfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import scipy.io as sio\n",
        "import scipy.sparse.linalg\n",
        "from scipy.sparse.linalg import eigsh\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch  \n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from utils_spectral import LB_FEM_sparse, EigendecompositionSparse, LB_cotan, Eigendecomposition\n",
        "from utils_mesh import load_off\n",
        "from utils_mesh import plot_colormap"
      ],
      "metadata": {
        "id": "PSYkKfq5FIqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load a 3D model as a triangular mesh"
      ],
      "metadata": {
        "id": "f1sV41KjFVPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this case the mesh is saved in a matlab-like file\n",
        "shape_path1 = './pose.mat'\n",
        "dtype = 'float32'\n",
        "\n",
        "x = sio.loadmat(shape_path1)\n",
        "\n",
        "# Converting the dictionary in convenient variables, and moving them on the GPU\n",
        "vertices = torch.from_numpy(x['M']['VERT'][0,0].astype(dtype)).cuda()\n",
        "triv = torch.from_numpy(x['M']['TRIV'][0,0].astype('long')).cuda()-1"
      ],
      "metadata": {
        "id": "U4Nj-WCjFJSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We provide two ways to compute the LBO in the supporting utilities: a sparse one and a dense one. They produce the same results, but for different applications you may prefer one instead of the other."
      ],
      "metadata": {
        "id": "44BYfCZZFX6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of eigenvalues we would compute\n",
        "k = 90\n",
        "\n",
        "# Sparse LBO\n",
        "L_sym_sp, A_sp, Ainv_sp = LB_FEM_sparse(vertices,triv.long())\n",
        "\n",
        "evecs_sp, evals_sp = EigendecompositionSparse(L_sym_sp.values(), L_sym_sp.indices(), torch.tensor(k), torch.tensor(L_sym_sp.shape[-1]))\n",
        "evecs_sp = evecs_sp * Ainv_sp[:,None]\n",
        "\n",
        "# Dense LBO\n",
        "W, A = LB_cotan(vertices ,triv.long())\n",
        "Ainv = A.rsqrt()\n",
        "L_sym = torch.mul(W, Ainv[None, :] * Ainv[:, None])  # <- INEFFICIENCY\n",
        "\n",
        "evecs, evals = Eigendecomposition(L_sym, torch.tensor(k), torch.tensor(L_sym.shape[-1]))\n",
        "evecs = evecs * Ainv[:,None]"
      ],
      "metadata": {
        "id": "IeEnl5wSFcTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing eigenvectors obtained by the two eigendecompositions"
      ],
      "metadata": {
        "id": "-a54wHAlGFdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = plot_colormap( [vertices]*3, [triv]*3,[evecs[:,i+1] for i in range(3)] )\n",
        "p.show()\n",
        "\n",
        "p = plot_colormap( [vertices]*3, [triv]*3,[evecs_sp[:,i+1] for i in range(3)] )\n",
        "p.show()"
      ],
      "metadata": {
        "id": "hL0gW57MGCvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the spectra"
      ],
      "metadata": {
        "id": "CAZAgo6FHxKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(evals.detach().cpu(), 'r', linewidth=4)    #Dense method\n",
        "plt.plot(evals_sp.detach().cpu(),'k--',linewidth=4) #Sparse method"
      ],
      "metadata": {
        "id": "2wQNUAIzHFEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coordinates Low Pass"
      ],
      "metadata": {
        "id": "-GLne85IIAMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 10\n",
        "\n",
        "evecs_trim = evecs[:,0:k]\n",
        "\n",
        "# Remember: the inner product is defined with the Areas!\n",
        "v = evecs[:,0:k] @ evecs_trim.T @ (A[:,None] * vertices)\n",
        "\n",
        "# Low pass representation compared to the original mesh\n",
        "p = plot_colormap([v, vertices], [triv]*2,[np.ones(v.shape[0]),np.ones(v.shape[0])] )\n",
        "p.show()"
      ],
      "metadata": {
        "id": "Sc9P1f5BHNJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also try on a more articulated shape."
      ],
      "metadata": {
        "id": "r3_KWNflgIum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading an humanoid shape\n",
        "with open(\"tr_reg_090.off\") as f:\n",
        "  v, f = load_off(f)\n",
        "\n",
        "vertices = torch.from_numpy(v.astype(dtype)).cuda()*1\n",
        "triv = torch.from_numpy(np.asarray(f).astype('long')).cuda()\n",
        "\n",
        "k = 50\n",
        "\n",
        "# Computing the eigenvectors\n",
        "L_sym_sp, A_sp, Ainv_sp = LB_FEM_sparse(vertices,triv.long())\n",
        "evecs, evals = EigendecompositionSparse(L_sym_sp.values(),L_sym_sp.indices(), torch.tensor(k), torch.tensor(L_sym_sp.shape[-1]))\n",
        "evecs = evecs * Ainv_sp[:,None]\n",
        "\n",
        "# Low\n",
        "evecs_trim = evecs[:,0:k]\n",
        "v = evecs_trim @ (evecs_trim.T * A_sp[None,:]) @ vertices\n",
        "\n",
        "p = plot_colormap([v]*3, [triv]*3,[np.ones(v.shape[0])] )\n",
        "p.show()"
      ],
      "metadata": {
        "id": "sap8caRqgLFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spectral Clustering (Segmentation)\n",
        "\n",
        "As a first application, we can cluster the surface using the spectral embedding of the shapes.\n",
        "\n",
        "The steps are:\n",
        "\n",
        "- Choosing the number of clusters\n",
        "- Running KMeans on the eigenvectors\n",
        "- Visualizing the clusters"
      ],
      "metadata": {
        "id": "60_du2NkInFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of cluster\n",
        "n_c = 6\n",
        "\n",
        "#KMeans\n",
        "kmeans = KMeans(n_clusters=n_c, random_state=1).fit(evecs[:,1:n_c].detach().cpu())\n",
        "\n",
        "# Visualization\n",
        "p = plot_colormap([vertices]*3, [triv]*3,[kmeans.labels_] )\n",
        "p.show()"
      ],
      "metadata": {
        "id": "fiDf-oWxJBfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can we expect that for two different shapes the result will be similar? The first eigenfunctions are pretty stable among objects of the same class, so they are good features to cluster the points."
      ],
      "metadata": {
        "id": "GO8Z8NOVgeaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"tr_reg_043.off\") as f:\n",
        "  v, f = load_off(f)\n",
        "\n",
        "vertices2 = torch.from_numpy(v.astype(dtype)).cuda()*1\n",
        "triv2 = torch.from_numpy(np.asarray(f).astype('long')).cuda()\n",
        "L_sym_sp, A_sp, Ainv_sp = LB_FEM_sparse(vertices2,triv2.long())\n",
        "evecs2, evals2 = EigendecompositionSparse(L_sym_sp.values(),L_sym_sp.indices(), torch.tensor(k), torch.tensor(L_sym_sp.shape[-1]))\n",
        "evecs2 = evecs2 * Ainv_sp[:,None]\n",
        "\n",
        "p = plot_colormap([vertices,vertices,vertices,vertices], [triv,triv,triv,triv],\n",
        "                  [evecs[:,1], evecs[:,2], evecs[:,3],evecs[:,4]] )\n",
        "p.show()\n",
        "\n",
        "p = plot_colormap([vertices2,vertices2,vertices2,vertices2], [triv2,triv2,triv2,triv2],\n",
        "                  [evecs2[:,1], evecs2[:,2], evecs2[:,3],evecs2[:,4]] )\n",
        "p.show()"
      ],
      "metadata": {
        "id": "k_3SYXczhBOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can compute the cluster also for the second shape."
      ],
      "metadata": {
        "id": "_Jm4miBZkZMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_c = 6\n",
        "kmeans2 = KMeans(n_clusters=n_c, random_state=1).fit(evecs2[:,1:n_c].detach().cpu())\n",
        "\n",
        "p = plot_colormap([vertices,vertices2], [triv,triv2]*3,[kmeans.labels_, kmeans2.labels_] )\n",
        "p.show()"
      ],
      "metadata": {
        "id": "UVOAaH_QKju2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using higher frequencies, the process becomes more unstable. Plotting the eigenvalues of the two shapes gives us a good intuition of this fact."
      ],
      "metadata": {
        "id": "YJrSjJEusUyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(evals.detach().cpu(), 'b', linewidth=4)\n",
        "plt.plot(evals2.detach().cpu(),'r',linewidth=4)"
      ],
      "metadata": {
        "id": "JbO12VV9Moav"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}