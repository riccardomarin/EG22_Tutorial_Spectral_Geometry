{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d09b549d",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/riccardomarin/EG22_Tutorial_Spectral_Geometry/blob/main/inverse/01_Isospectralization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a61160",
   "metadata": {},
   "source": [
    "In this notebook we will see tha application of some computational inverse geometry techniques to a couple of trivial examples.\n",
    "\n",
    "We want to solve the general optimization problem of:\n",
    "\n",
    "$\\arg\\min _{\\mathbf{X} \\in \\mathbb{R}^{n \\times d}}\\left\\|\\boldsymbol{\\lambda}\\left(\\boldsymbol{\\Delta}(\\mathbf{X})\\right)-\\boldsymbol{\\mu}\\right\\|_{\\omega}+\\rho_{X}(\\mathbf{X})$\n",
    "\n",
    "Reference: Cosmo, Luca, et al. \"Isospectralization, or how to hear shape, style, and correspondence.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.\n",
    "Related repositories:https://github.com/lcosmo/isospectralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1df4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "    \n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import utils_mesh \n",
    "from utils_spectral import LB_FEM_sparse as lbo, EigendecompositionSparse as eigh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd02777",
   "metadata": {},
   "source": [
    "Few considerations on computing the gradient of the laplacian:\n",
    "* if we keep the connectivity of the mesh fixed, the LBO operator is differentiable with respect to the point positions. It is indeed expressed in terms of the lenght (or angles) of each edge, which is computed from the 3d coordinates of each point.\n",
    "\n",
    "* Eigenvalues of any matrix A are also differentiable with respect to the entries of the matrix\n",
    "\n",
    "* We can thus exploit autodifferntiation capabilities of torch (or the autodiff package you may prefer) to automatically compute the eigenvalues w.r.t. the points coordinates of the input mesh.\n",
    "\n",
    "Let's start with a trivial example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f19f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_1 = torch.tensor([[0,0,0],[0,1,0],[1,0,0]]).double()\n",
    "triangle_2 = torch.tensor([[0,0,0],[0,2,0],[1,0,0]]).double()\n",
    "tri = torch.tensor([[0,1,2]])\n",
    "\n",
    "utils_mesh.plot_colormap([triangle_1,triangle_2],[tri]*2,[None]*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fab3a7",
   "metadata": {},
   "source": [
    "We can compute and visualize the first eigenvectors and eigenvalues of the two tringular meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078262f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_spectral import LB_cotan as lbo, Eigendecomposition as eigh\n",
    "\n",
    "stiff, lumped_mass = lbo(triangle_1,tri)\n",
    "\n",
    "#we have to convert the generalized eigendecomposition problem to the simpler eigendecomposition of hermitian matrices\n",
    "inv_sqrt_mass = lumped_mass.rsqrt()\n",
    "L1 = inv_sqrt_mass[:,None]*stiff*inv_sqrt_mass[None,:]\n",
    "evecs_1,evals_1 = eigh(L1,3)\n",
    "\n",
    "stiff, lumped_mass = lbo(triangle_2,tri)\n",
    "inv_sqrt_mass = lumped_mass.rsqrt()\n",
    "L2 = inv_sqrt_mass[:,None]*stiff*inv_sqrt_mass[None,:]\n",
    "evecs_2,evals_2 = eigh(L2,3)\n",
    "\n",
    "fig = utils_mesh.plot_colormap([triangle_1]*3,[tri]*3,[e for e in evecs_1])\n",
    "fig.show()\n",
    "\n",
    "fig = utils_mesh.plot_colormap([triangle_2]*3,[tri]*3,[e for e in evecs_2])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e83534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(evals_1.data.cpu())\n",
    "plt.plot(evals_2.data.cpu())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438624cc",
   "metadata": {},
   "source": [
    "### Can we deform triangle_2 into trinagle_1 just knowing the eigenvalues of traingle_1?\n",
    "Let's write down it as an optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059b6a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_evals = evals_1.detach().clone().cuda()\n",
    "\n",
    "X = torch.nn.Parameter(triangle_2.detach().clone().cuda()) # we start from the original vertex coordinates of triangle_2\n",
    "tri = tri.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=[X],lr=5e-3)\n",
    "\n",
    "for i in range(1000): #we now enter the iterative optimization loop\n",
    "    optimizer.zero_grad() #usual pytorch code for gradient descent\n",
    "    \n",
    "    stiff, lumped_mass = lbo(X,tri)\n",
    "    inv_sqrt_mass = lumped_mass.rsqrt()\n",
    "    Lopt = inv_sqrt_mass[:,None]*stiff*inv_sqrt_mass[None,:]\n",
    "    _,evals_opt = eigh(Lopt,3)\n",
    "    \n",
    "    loss = torch.sum((evals_opt-target_evals)[1:]**2) #the first eigenvalue will always be almost 0\n",
    "    \n",
    "    loss.backward() #let's compute the gradient w.r.t. optimiziation parameters\n",
    "    \n",
    "#     print(X.grad)\n",
    "    if i %10==0:\n",
    "        print('Loss: %.2e' % loss)\n",
    "    \n",
    "    optimizer.step()#usual pytorch code for gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda19de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(evals_1.data.cpu(),'o')\n",
    "plt.plot(evals_opt.data.cpu(),'r')\n",
    "plt.plot(evals_2.data.cpu(),'b')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc78bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = utils_mesh.plot_colormap([triangle_2, X.data.cpu(), triangle_1],[tri]*3,[None]*3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa26475",
   "metadata": {},
   "source": [
    "As we already discussed, in the general case isospectral != isometric.\n",
    "\n",
    "Moreover, you may have noticed that we are using just the first 3 eigenvalues of the triangle (we are limited by the first order FEM). Since the first eigenvalue is always null, we can fix just just 2 dof, while a generic triangle has 3.\n",
    "\n",
    "But what if we have some prior domain knowlege on the domain of the shape that we want to reconstruct?\n",
    "\n",
    "Assume, for instance, that we are interested in (almost) orthogonal triangles.\n",
    "we can encode this information as a regularizer (possibly an hard constraint) in the optimization problem:\n",
    "\n",
    "we want (x[2]-X[0]) to be orthogonal to (X[1]-X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9018d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_evals = evals_1.detach().clone().cuda()\n",
    "\n",
    "X = torch.nn.Parameter(triangle_2.detach().clone().cuda()) # we start from the original vertex coordinates of triangle_2\n",
    "tri = tri.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=[X],lr=1e-2)\n",
    "\n",
    "import time\n",
    "t=time.time()\n",
    "for i in range(2000): #we now enter the iterative optimization loop\n",
    "    optimizer.zero_grad() #usual pytorch code for gradient descent\n",
    "    \n",
    "    stiff, lumped_mass = lbo(X,tri)\n",
    "    inv_sqrt_mass = lumped_mass.rsqrt()\n",
    "    Lopt = inv_sqrt_mass[:,None]*stiff*inv_sqrt_mass[None,:]\n",
    "    _,evals_opt = eigh(Lopt,3)\n",
    "    \n",
    "    loss_eig = torch.sum((evals_opt-target_evals)[1:]**2) #the first eigenvalue will always be almost 0\n",
    "    loss_ortho = 1e2*torch.dot(X[2]-X[0], X[1]-X[0])**2\n",
    "    loss = loss_eig+loss_ortho\n",
    "    \n",
    "    loss.backward() #let's compute the gradient w.r.t. optimiziation parameters\n",
    "\n",
    "    optimizer.step()#usual pytorch code for gradient descent\n",
    "    if i %10==0:\n",
    "        print('Loss: %.2e' % loss)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(evals_1.data.cpu(),'o')\n",
    "plt.plot(evals_opt.data.cpu(),'r')\n",
    "plt.plot(evals_2.data.cpu(),'b')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c27d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = utils_mesh.plot_colormap([triangle_2, X.data.cpu(), triangle_1],[tri]*3,[None]*3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac1bff1",
   "metadata": {},
   "source": [
    "Attention: Rigid transformations are isoemtries.\n",
    "Have a look to the metric of the optimized triangle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c44ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check edge lengths:\n",
    "print(torch.norm(X[0]-X[1]))\n",
    "print(torch.norm(X[1]-X[2]))\n",
    "print(torch.norm(X[2]-X[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ed9f6",
   "metadata": {},
   "source": [
    "### A more interesting (and harder) example\n",
    "\n",
    "What about \"general\" planar shapes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d998972",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERT1,TRIV1 = utils_mesh.load_ply('../data/mickey.ply')\n",
    "VERT2,TRIV2 = utils_mesh.load_ply('../data/oval.ply')\n",
    "\n",
    "VERT1 = torch.tensor(VERT1).double().cuda()\n",
    "VERT2 = torch.tensor(VERT2).double().cuda()\n",
    "TRIV1 = torch.tensor(TRIV1).long().cuda()\n",
    "TRIV2 = torch.tensor(TRIV2).long().cuda()\n",
    "\n",
    "fig = utils_mesh.plot_colormap([VERT1,VERT2],[TRIV1, TRIV2],[None]*2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be14b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_spectral import LB_cotan as lbo, Eigendecomposition as eigh\n",
    "\n",
    "#how many eigenvalues do we wish to align? Higher eigenvalues are usually dominated by discretization noise\n",
    "k = 20\n",
    "\n",
    "stiff, lumped_mass = lbo(VERT1,TRIV1)\n",
    "inv_sqrt_mass = lumped_mass.rsqrt()\n",
    "L1 = inv_sqrt_mass[:,None]*stiff*inv_sqrt_mass[None,:]\n",
    "evecs_1,evals_1 = eigh(L1,k)\n",
    "\n",
    "stiff, lumped_mass = lbo(VERT2,TRIV2)\n",
    "inv_sqrt_mass = lumped_mass.rsqrt()\n",
    "L2 = inv_sqrt_mass[:,None]*stiff*inv_sqrt_mass[None,:]\n",
    "evecs_2,evals_2 = eigh(L2,k)\n",
    "\n",
    "#extract the vertex indexes for each edge of the mesh, it will be used later to compute edges' length \n",
    "edge_indexes2 = np.nonzero(stiff.data.cpu().triu(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d310d",
   "metadata": {},
   "source": [
    "There are some problems we need to take care of in the optimization process:\n",
    "* Triangle flips should not be allowed\n",
    "* Very skewed triangles cause numerical instability (especially if using first order Laplacian approximation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2351a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.linalg\n",
    "from torch.nn.functional import normalize\n",
    "target_evals = evals_1.detach().clone()\n",
    "\n",
    "# X = torch.nn.Parameter(VERT2.detach().clone().cuda()) # we start from the original vertex coordinates of triangle_2\n",
    "tri = TRIV2.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=[X],lr=5e-3)\n",
    "\n",
    "for i in range(1000): #we now enter the iterative optimization loop\n",
    "    optimizer.zero_grad() #usual pytorch code for gradient descent\n",
    "    \n",
    "    stiff, lumped_mass = lbo(X,tri)\n",
    "    inv_sqrt_mass = lumped_mass.rsqrt()\n",
    "    Lopt = inv_sqrt_mass[:,None]*stiff*inv_sqrt_mass[None,:]\n",
    "    _,evals_opt = eigh(Lopt,k)\n",
    "\n",
    "    \n",
    "    loss = torch.sum((evals_opt-target_evals)[1:]**2/torch.arange(1,k).to(X.device)) #the first eigenvalue will always be almost 0\n",
    "    \n",
    "    #regularizers\n",
    "    \n",
    "    #triangle flips\n",
    "    tripts = X[tri]\n",
    "    loss_flip =  (torch.cross((-tripts[:,1,:]+tripts[:,0,:]),(tripts[:,2,:]-tripts[:,0,:]),dim=1)[:,-1]+1e-3).relu().pow(2).sum()\n",
    "    loss_flip += (torch.cross((-tripts[:,2,:]+tripts[:,1,:]),(tripts[:,0,:]-tripts[:,1,:]),dim=1)[:,-1]+1e-3).relu().pow(2).sum()\n",
    "    loss_flip += (torch.cross((-tripts[:,0,:]+tripts[:,2,:]),(tripts[:,1,:]-tripts[:,2,:]),dim=1)[:,-1]+1e-3).relu().pow(2).sum()\n",
    "    loss = loss + 1e5*loss_flip\n",
    "    \n",
    "    #edge length\n",
    "    loss_len = (X[edge_indexes2[:,0],:]-X[edge_indexes2[:,1],:]).pow(2).sum(-1).mean()\n",
    "    loss = loss  + 1e1*loss_len\n",
    "                         \n",
    "    \n",
    "    loss.backward() #let's compute the gradient w.r.t. optimiziation parameters\n",
    "    torch.nn.utils.clip_grad_norm_([X], 1e-3)\n",
    "#     print(X.grad)\n",
    "    if i %10==0:\n",
    "        print('Loss: %.2e' % loss)\n",
    "#         fig = utils_mesh.plot_colormap([ X.data.cpu()],[TRIV2]*3,[None]*3,wireframe=True)\n",
    "#         fig.show()\n",
    "#         print(time.time()-t)\n",
    "#         t=time.time()\n",
    "    optimizer.step()#usual pytorch code for gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a732e7",
   "metadata": {},
   "source": [
    "The initial triangulation is not always ideal for representing the target shape. Resampling the optimized shape every once in a while would help the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93538c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = torch.load('results/mickey_opt.pt')\n",
    "\n",
    "fig = utils_mesh.plot_colormap([ VERT1, X.data.cpu()],[TRIV1,TRIV2],[None]*2,wireframe=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad4f43",
   "metadata": {},
   "source": [
    "## 3D Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f35c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERT1,TRIV1 = utils_mesh.load_ply('../data/round_cuber_out.ply')\n",
    "VERT2,TRIV2 = utils_mesh.load_ply('../data/round_cuber.ply')\n",
    "\n",
    "VERT1 = torch.tensor(VERT1).double().cuda()\n",
    "VERT2 = torch.tensor(VERT2).double().cuda()\n",
    "TRIV1 = torch.tensor(TRIV1).long().cuda()\n",
    "TRIV2 = torch.tensor(TRIV2).long().cuda()\n",
    "\n",
    "fig = utils_mesh.plot_colormap([VERT1,VERT2],[TRIV1, TRIV2],[None]*2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afa991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30\n",
    "\n",
    "stiff_1, lumped_mass_1 = lbo(VERT1,TRIV1)\n",
    "inv_sqrt_mass_1 = lumped_mass_1.rsqrt()\n",
    "L1 = inv_sqrt_mass_1[:,None]*stiff_1*inv_sqrt_mass_1[None,:]\n",
    "evecs_1,evals_1 = eigh(L1,k)\n",
    "\n",
    "stiff_2, lumped_mass_2 = lbo(VERT2,TRIV2)\n",
    "inv_sqrt_mass_2 = lumped_mass_2.rsqrt()\n",
    "L2 = inv_sqrt_mass_2[:,None]*stiff_2*inv_sqrt_mass_2[None,:]\n",
    "evecs_2,evals_2 = eigh(L2,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab652f6",
   "metadata": {},
   "source": [
    "###  Challenges of 3D shapes:\n",
    "* Even if triangle flips are not in general possible in a 3D embedding, ugly triangles and spikes are still a problem. We can alleviate this problem adding a smoothness prior.\n",
    "* In 3D shapes there exist many \"non-meaningful\" isometries. For instance, flipping any protuberation inside out is a valid isometry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e09cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.linalg\n",
    "from torch.nn.functional import normalize\n",
    "target_evals = evals_1.detach().clone()\n",
    "\n",
    "# iX = VERT2.detach().clone().cuda()\n",
    "# dX = torch.nn.Parameter((VERT2*0).detach().clone().cuda()) # we start from the original vertex coordinates of triangle_2\n",
    "tri = TRIV2.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=[dX],lr=1e-3)\n",
    "\n",
    "for i in range(5000): #we now enter the iterative optimization loop\n",
    "    optimizer.zero_grad() #usual pytorch code for gradient descent\n",
    " \n",
    "    X = iX+dX\n",
    "    stiff_o, lumped_mass_o = lbo(X,tri)\n",
    "    inv_sqrt_mass_o = lumped_mass_o.rsqrt()\n",
    "    Lopt = inv_sqrt_mass_o[:,None]*stiff_o*inv_sqrt_mass_o[None,:]\n",
    "    _,evals_opt = eigh(Lopt,k)\n",
    "\n",
    "    \n",
    "    loss = torch.sum((evals_opt-target_evals)[1:]**2/torch.arange(1,k).to(X.device)) #the first eigenvalue will always be almost 0\n",
    "    \n",
    "    ## regularizers \n",
    "    \n",
    "    #curvature\n",
    "    loss_curv = 1e1*torch.norm((stiff_o)@dX)\n",
    "    loss = loss + loss_curv\n",
    "\n",
    "    #volume\n",
    "    tripts = X[tri]\n",
    "    cross =  torch.cross((tripts[:,1,:]-tripts[:,0,:]),(tripts[:,1,:]-tripts[:,2,:]),dim=1)\n",
    "    volume = 2e0*torch.sum(tripts.sum(1)*cross)\n",
    "    loss = loss-volume\n",
    "        \n",
    "    \n",
    "    loss.backward() #let's compute the gradient w.r.t. optimiziation parameters\n",
    "    torch.nn.utils.clip_grad_norm_([X], 1e-3)\n",
    "#     print(X.grad)\n",
    "    if i %10==0:\n",
    "        print('Loss: %.2e (%.2e)' % (loss,loss_curv))\n",
    "#         fig = utils_mesh.plot_colormap([ X.data.cpu()],[TRIV2]*3,[None]*3,wireframe=True)\n",
    "#         fig.show()\n",
    "#         print(time.time()-t)\n",
    "#         t=time.time()\n",
    "    optimizer.step()#usual pytorch code for gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef4e05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#X = torch.load('results/cube_noreg.pt')\n",
    "#X = torch.load('results/cube_res_all.pt')\n",
    "#X = torch.load('results/cube_res_in.pt')\n",
    "\n",
    "err = torch.norm(((inv_sqrt_mass[:,None]**2)*stiff)@dX,dim=-1)\n",
    "\n",
    "fig = utils_mesh.plot_colormap([ VERT1, X.data.cpu()],[TRIV1,TRIV2],[None,err],wireframe=True)\n",
    "fig.show()\n",
    "\n",
    "plt.plot(target_evals.detach().cpu())\n",
    "plt.plot(evals_opt.detach().cpu())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(target_evals.detach().cpu()-evals_opt.detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d698fd4a",
   "metadata": {},
   "source": [
    "Also eigenvectors are now more similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c040390",
   "metadata": {},
   "outputs": [],
   "source": [
    "evecs_opt,evals_opt = eigh(Lopt,k)\n",
    "evecs_opt = evecs_opt * inv_sqrt_mass_o[:,None]\n",
    "\n",
    "evecs_1,evals_1 = eigh(L1,k)\n",
    "evecs_1 = evecs_1 * inv_sqrt_mass_1[:,None]\n",
    "\n",
    "evecs_2,evals_2 = eigh(L2,k)\n",
    "evecs_2 = evecs_2 * inv_sqrt_mass_2[:,None]\n",
    "\n",
    "print('Original eigenvectors')\n",
    "fig = utils_mesh.plot_colormap([VERT2]*3,[TRIV2]*3,[evecs_2[:,1],evecs_2[:,2],evecs_2[:,10]])\n",
    "fig.show()\n",
    "\n",
    "print('Optimized eigenvectors')\n",
    "fig = utils_mesh.plot_colormap([X.data.cpu()]*3,[TRIV2]*3,[evecs_opt[:,1],evecs_opt[:,2],evecs_opt[:,10]])\n",
    "fig.show()\n",
    "\n",
    "print('Target eigenvectors')\n",
    "fig = utils_mesh.plot_colormap([VERT1]*3,[TRIV1]*3,[evecs_1[:,1],evecs_1[:,2],evecs_1[:,10]])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71bf118",
   "metadata": {},
   "source": [
    "This affects also the quality of the functional map, and can be used as a preconditioning step of the shapes to be matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb0d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CA=B\n",
    "# CA=psi*phi'\n",
    "\n",
    "C_before = (evecs_1.t()*inv_sqrt_mass_1[None,:])@evecs_2\n",
    "C_after  = (evecs_1.t()*inv_sqrt_mass_1[None,:])@evecs_opt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,6))\n",
    "ax[0].imshow(C_before.data.cpu().abs(),cmap=plt.get_cmap('Reds'))\n",
    "ax[0].set_title('before')\n",
    "ax[1].imshow(C_after.data.cpu().abs(),cmap=plt.get_cmap('Reds'))\n",
    "ax[1].set_title('after')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
